# ðŸ“š All About Agents

Welcome to our comprehensive resource collection for AI agents. This page curates valuable tools, frameworks, research papers, and learning materials to help you understand and build sophisticated agent systems.

---

## Table of Contents

!!! abstract "Resource Categories"
    1. [Agent Frameworks](#agent-frameworks)
    2. [Agent Memory](#agent-memory)
    3. [Papers](#papers)
    4. [Evaluation](#evaluation)

---

## Agent Frameworks

!!! info "Popular Agent Development Frameworks"
    Comprehensive frameworks for building and deploying AI agents across different domains.

- **MiroFlow**: Build, manage, and scale your AI agents with ease
    - [:material-github: GitHub](https://github.com/MiroMindAI/MiroFlow)

- **Youtu-Agent**: A simple yet powerful agent framework that delivers with open-source models
    - [:material-github: GitHub](https://github.com/TencentCloudADP/youtu-agent)

- **OpenManus**: No fortress, purely open ground. OpenManus is Coming
    - [:material-github: GitHub](https://github.com/FoundationAgents/OpenManus)

- **OpenBB Platform**: Financial data platform for analysts, quants and AI agents 
    - [:material-link: Project](https://github.com/OpenBB-finance/OpenBB)

---

## Agent Memory

!!! tip "Memory Systems for Persistent Agent Intelligence"
    Advanced memory solutions for building agents with long-term context and learning capabilities.

- **Mem0**: Building Production- Ready AI Agents with Scalable Long-Term Memory
    - [:material-github: GitHub](https://github.com/mem0ai/mem0)

- **memobase**: Profile-Based Long-Term Memory for AI Applications
    - [:material-github: GitHub](https://github.com/memodb-io/memobase)

- **Memento**: Fine-tuning LLM Agents without Fine-tuning LLMs
    - [:material-file-document: Paper](https://arxiv.org/abs/2508.16153) Â· [:material-github: GitHub](https://github.com/Agent-on-the-Fly/Memento)

---


## Papers

!!! note "Research Papers & Publications"
    Latest research in agent systems, methodologies, and theoretical foundations.

- **Profile-Aware Maneuvering**: A Dynamic Multi-Agent System for Robust GAIA Problem Solving by AWorld 
    - [:material-file-document: Paper](https://arxiv.org/abs/2508.09889)

- **AFlow**: Automating Agentic Workflow Generation 
    - [:material-file-document: Paper](https://arxiv.org/abs/2410.10762)

- **AgentFly**: Fine-tuning LLM Agents without Fine-tuning LLMs 
    - [:material-file-document: Paper](https://arxiv.org/abs/2508.16153v2)

- **Throttling Web Agents Using Reasoning Gates**
    - [:material-file-document: Paper](https://arxiv.org/abs/2509.01619)

- **The Landscape of Agentic Reinforcement Learning for LLMs**: A Survey
    - [:material-file-document: Paper](https://arxiv.org/abs/2509.02547)

---



## Evaluation

!!! success "Benchmarks & Evaluation Frameworks"
    Comprehensive evaluation tools and benchmarks for measuring agent performance across various tasks.

- **LiveMCP-101**: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries 
    - [:material-file-document: Paper](https://arxiv.org/abs/2508.15760)

- **BrowseComp-Plus**: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent 
    - [:material-file-document: Paper](https://arxiv.org/abs/2508.06600)

- **HotpotQA**: A Dataset for Diverse, Explainable Multi-hop Question Answering
    - [:material-file-document: Paper](https://arxiv.org/abs/1809.09600)

- **GAIA**: a benchmark for General AI Assistants 
    - [:material-file-document: Paper](https://arxiv.org/abs/2311.12983) Â· [:material-trophy: Leaderboard](https://huggingface.co/spaces/gaia-benchmark/leaderboard)

- **xbench**: Tracking Agents Productivity Scaling with Profession-Aligned Real-World Evaluations 
    - [:material-file-document: Paper](https://arxiv.org/abs/2506.13651)

- **MCP-Universe**: Benchmarking Large Language Models with Real-World Model Context Protocol Servers 
    - [:material-file-document: Paper](https://arxiv.org/abs/2508.14704)

- **FutureX**: An Advanced Live Benchmark for LLM Agents in Future Prediction 
    - [:material-file-document: Paper](https://arxiv.org/abs/2508.11987)

- **Terminal-Bench**: the benchmark for testing AI agents in real terminal environments 
    - [:material-github: GitHub](https://github.com/laude-institute/terminal-bench)

- **Gaia2 and ARE**: Empowering the Community to Evaluate Agents
    - [:material-file-document: Blog Post](https://huggingface.co/blog/gaia2)

---

!!! info "Documentation Info"
    **Last Updated:** September 2025 Â· **Doc Contributor:** Team @ MiroMind AI